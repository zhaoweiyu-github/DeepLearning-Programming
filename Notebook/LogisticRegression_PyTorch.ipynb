{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu102\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference: [Logistic Regression with PyTorch](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_logistic_regression/) and [Basics of Neural Network](http://www.ai-start.com/dl2017/html/lesson1-week2.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic regression and softmax\n",
    "\n",
    "<img src=\"./SchematicImages/logistic_regression_1.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A logistic regression case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loading training and test dataset and make it iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes an image dataset for PyTorch'\n",
    "    def __init__(self, list_files, labels, transform = None):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_files = list_files\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_files)\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        file_dir = self.list_files[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        image = PIL.Image.open(file_dir)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        X = image\n",
    "        y = torch.tensor(self.labels[file_dir])\n",
    "\n",
    "        return X, y\n",
    "\n",
    "data_dir = \"/mnt/Storage/home/yuzhaowei/.keras/datasets/flower_photos\"\n",
    "labels = {}\n",
    "daisy_images = [os.path.join((data_dir), \"daisy\") + \"/\" + i for i in os.listdir(os.path.join((data_dir), \"daisy\"))]\n",
    "rose_images = [os.path.join((data_dir), \"roses\") + \"/\" + i for i in os.listdir(os.path.join((data_dir), \"roses\"))]\n",
    "sunflowers_images = [os.path.join((data_dir), \"sunflowers\") + \"/\" + i for i in os.listdir(os.path.join((data_dir), \"sunflowers\"))]\n",
    "samples = np.concatenate([np.random.choice(daisy_images, 500), np.random.choice(rose_images, 500), np.random.choice(sunflowers_images, 500)])\n",
    "\n",
    "for image in daisy_images:\n",
    "    labels[image] = 0 # dasiy\n",
    "for image in rose_images:\n",
    "    labels[image] = 1 # roses\n",
    "for image in sunflowers_images:\n",
    "    labels[image] = 2 # sunflowers\n",
    "\n",
    "class Rescale():\n",
    "    \"\"\"Reize image in a sample to a given size\"\"\"\n",
    "    def __call__(self, image):\n",
    "        image_resize = np.array(T.Resize(size = (224, 224))(image))\n",
    "        return(image_resize)\n",
    "    \n",
    "# Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8\n",
    "composed = T.Compose([Rescale(), T.ToTensor()]) # composed two treatments for input images    \n",
    "        \n",
    "    \n",
    "dataset = Dataset(samples, labels, transform = composed)\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, lengths = [int(1500 * 0.8), int(1500 * 0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.9961, 0.9882, 0.9843,  ..., 0.7529, 0.8039, 0.8824],\n",
       "          [0.9961, 0.9882, 0.9843,  ..., 0.8667, 0.8980, 0.9098],\n",
       "          [0.9961, 0.9882, 0.9843,  ..., 0.9176, 0.9137, 0.8980],\n",
       "          ...,\n",
       "          [0.5843, 0.5647, 0.5451,  ..., 0.9216, 0.9255, 0.9255],\n",
       "          [0.6000, 0.5804, 0.5647,  ..., 0.9294, 0.9216, 0.9216],\n",
       "          [0.5922, 0.5843, 0.5569,  ..., 0.9294, 0.9255, 0.9294]],\n",
       " \n",
       "         [[0.7843, 0.7961, 0.8000,  ..., 0.6941, 0.7216, 0.8196],\n",
       "          [0.7843, 0.7961, 0.8000,  ..., 0.8078, 0.8392, 0.8667],\n",
       "          [0.7882, 0.8000, 0.8000,  ..., 0.8549, 0.8549, 0.8510],\n",
       "          ...,\n",
       "          [0.6667, 0.6510, 0.6275,  ..., 0.8588, 0.8627, 0.8627],\n",
       "          [0.6667, 0.6549, 0.6314,  ..., 0.8667, 0.8667, 0.8667],\n",
       "          [0.6706, 0.6510, 0.6196,  ..., 0.8627, 0.8667, 0.8627]],\n",
       " \n",
       "         [[0.6863, 0.7020, 0.7216,  ..., 0.6549, 0.7020, 0.8078],\n",
       "          [0.6863, 0.7020, 0.7216,  ..., 0.7608, 0.8039, 0.8314],\n",
       "          [0.6902, 0.7059, 0.7216,  ..., 0.8510, 0.8471, 0.8275],\n",
       "          ...,\n",
       "          [0.3098, 0.3020, 0.2627,  ..., 0.8588, 0.8627, 0.8627],\n",
       "          [0.3216, 0.3176, 0.2824,  ..., 0.8667, 0.8627, 0.8627],\n",
       "          [0.3176, 0.3098, 0.2745,  ..., 0.8627, 0.8627, 0.8627]]]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# dataset size\n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the model goes through the whole 1200 images once, learning how to classify 3 groups of flowers, it's consider 1 epoch. \n",
    "\n",
    "However, there's a concept of batch size where it means the model would look at 100 images before updating the model's weights, thereby learning. When the model updates its weights (parameters) after looking at all the images, this is considered 1 iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We arbitrarily set 100 iterations here which means the model would update 100 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we would like to go through 100 iterations, this implies we would have 100 / 1200 * 120 = 10 epochs as each epoch has 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "num_epochs = n_iters / (len(train_set) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-e787f1fbcdca>:10: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  isinstance(train_generator, collections.Iterable)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6,\n",
    "         'drop_last' : True # set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size.\n",
    "         }\n",
    "train_generator = torch.utils.data.DataLoader(train_set, **params)\n",
    "test_generator = torch.utils.data.DataLoader(test_set, **params)\n",
    "\n",
    "import collections\n",
    "isinstance(train_generator, collections.Iterable)\n",
    "isinstance(test_generator, collections.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as linear regression! \n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        # And we're feeding the model with n*n images, and output are number of classification groups.\n",
    "        self.linear = nn.Linear(input_dim, output_dim)  # input dim = 3 * 224 * 224, output_dim = 3\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return(out)\n",
    "    \n",
    "input_dim = 3 * 224 * 224\n",
    "output_dim = 3\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 instantiate loss class (logistic regression: cross entropy loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.CrossEntropyLoss() does 2 things at the same time.\n",
    "\n",
    "1. Computes softmax (logistic/softmax function)\n",
    "2. Computes cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 instantiate optimizer class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculates the parameters' gradients and update them subsequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process:\n",
    "    1. Convert inputs/labels to tensors with gradients\n",
    "    2. Clear gradient buffets\n",
    "    3. Get output given inputs\n",
    "    4. Get loss\n",
    "    5. Get gradients w.r.t. parameters\n",
    "    6. Update parameters using gradientsparameters = parameters - learning_rate * parameters_gradients\n",
    "    7. REPEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10. Loss: 3.3807289600372314. Accuracy: 51.25\n",
      "Iteration: 20. Loss: 2.110201120376587. Accuracy: 55.83333206176758\n",
      "Iteration: 30. Loss: 0.7504737973213196. Accuracy: 66.25\n",
      "Iteration: 40. Loss: 0.6078311204910278. Accuracy: 67.08333587646484\n",
      "Iteration: 50. Loss: 2.7222421169281006. Accuracy: 58.75\n",
      "Iteration: 60. Loss: 0.4933057427406311. Accuracy: 68.33333587646484\n",
      "Iteration: 70. Loss: 1.7783819437026978. Accuracy: 57.91666793823242\n",
      "Iteration: 80. Loss: 0.9139341711997986. Accuracy: 64.58333587646484\n",
      "Iteration: 90. Loss: 3.2309868335723877. Accuracy: 46.25\n",
      "Iteration: 100. Loss: 1.1253330707550049. Accuracy: 64.58333587646484\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_generator):\n",
    "        # Load images as Variable\n",
    "        images = images.view(-1, 3*224*224).requires_grad_()\n",
    "        # images = images.requires_grad_()\n",
    "        labels = labels\n",
    "        # print(labels)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        # print(outputs)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 10 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_generator:\n",
    "                # Load images to a Torch Variable\n",
    "                images = images.view(-1, 3*224*224).requires_grad_()\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7373, 0.7490, 0.7647,  ..., 0.4353, 0.4392, 0.4431],\n",
       "        [0.8039, 0.7961, 0.8039,  ..., 0.0196, 0.0235, 0.0235],\n",
       "        [0.6863, 0.6863, 0.6863,  ..., 0.2549, 0.2549, 0.2549],\n",
       "        ...,\n",
       "        [0.5686, 0.5765, 0.5843,  ..., 0.2118, 0.2078, 0.2000],\n",
       "        [0.6392, 0.6431, 0.6431,  ..., 0.6784, 0.6784, 0.6784],\n",
       "        [1.0000, 0.9922, 0.9961,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 0, 0,  ..., 1, 1, 1],\n",
       "          [1, 0, 0,  ..., 1, 1, 1],\n",
       "          [1, 0, 0,  ..., 1, 1, 1]],\n",
       " \n",
       "         [[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 0, 0,  ..., 1, 1, 1],\n",
       "          [1, 0, 0,  ..., 1, 1, 1],\n",
       "          [1, 0, 0,  ..., 1, 1, 1]],\n",
       " \n",
       "         [[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 0, 0,  ..., 1, 1, 1],\n",
       "          [1, 0, 0,  ..., 1, 1, 1],\n",
       "          [1, 0, 0,  ..., 1, 1, 1]]], dtype=torch.uint8),\n",
       " 'roses')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[193, 193, 193,  ..., 108, 108, 106],\n",
       "          [190, 190, 190,  ..., 108, 108, 106],\n",
       "          [187, 186, 186,  ..., 108, 108, 106],\n",
       "          ...,\n",
       "          [ 91,  89,  88,  ...,  76,  73,  73],\n",
       "          [ 90,  88,  88,  ...,  76,  73,  73],\n",
       "          [ 90,  88,  88,  ...,  76,  73,  73]],\n",
       " \n",
       "         [[183, 183, 183,  ...,  84,  84,  82],\n",
       "          [180, 180, 180,  ...,  84,  84,  82],\n",
       "          [177, 176, 176,  ...,  84,  84,  82],\n",
       "          ...,\n",
       "          [ 90,  88,  87,  ...,  58,  57,  57],\n",
       "          [ 89,  87,  87,  ...,  58,  57,  57],\n",
       "          [ 89,  87,  87,  ...,  58,  57,  57]],\n",
       " \n",
       "         [[173, 173, 173,  ...,  58,  58,  56],\n",
       "          [170, 170, 170,  ...,  58,  58,  56],\n",
       "          [167, 166, 166,  ...,  58,  58,  56],\n",
       "          ...,\n",
       "          [ 60,  58,  57,  ...,  21,  21,  21],\n",
       "          [ 59,  57,  57,  ...,  21,  21,  21],\n",
       "          [ 59,  57,  57,  ...,  21,  21,  21]]], dtype=torch.uint8),\n",
       " 'daisy')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1, 35,  0],\n",
       "        [25, 39,  3],\n",
       "        [27, 44,  0],\n",
       "        ...,\n",
       "        [29, 45,  0],\n",
       "        [25, 41,  2],\n",
       "        [21, 38,  2]],\n",
       "\n",
       "       [[11, 32,  0],\n",
       "        [31, 39,  0],\n",
       "        [41, 50,  3],\n",
       "        ...,\n",
       "        [35, 54,  0],\n",
       "        [25, 47,  1],\n",
       "        [18, 39,  0]],\n",
       "\n",
       "       [[13, 38,  0],\n",
       "        [29, 48,  2],\n",
       "        [45, 57,  7],\n",
       "        ...,\n",
       "        [40, 62,  0],\n",
       "        [27, 51,  1],\n",
       "        [18, 41,  0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[16, 38,  2],\n",
       "        [15, 42,  1],\n",
       "        [13, 46,  3],\n",
       "        ...,\n",
       "        [ 1, 27,  0],\n",
       "        [ 0, 21,  0],\n",
       "        [ 0, 15,  0]],\n",
       "\n",
       "       [[12, 33,  2],\n",
       "        [10, 36,  0],\n",
       "        [10, 41,  0],\n",
       "        ...,\n",
       "        [ 2, 28,  1],\n",
       "        [ 1, 20,  0],\n",
       "        [ 1, 15,  0]],\n",
       "\n",
       "       [[16, 36,  0],\n",
       "        [12, 33,  0],\n",
       "        [10, 34,  2],\n",
       "        ...,\n",
       "        [ 1, 27,  0],\n",
       "        [ 0, 24,  0],\n",
       "        [ 0, 20,  0]]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
